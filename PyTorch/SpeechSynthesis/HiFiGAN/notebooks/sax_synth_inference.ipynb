{
 "cells": [
  {
   "cell_type": "raw",
   "id": "433bcc19-7e73-4022-bd62-271ebde1b711",
   "metadata": {},
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87066394-dd52-4d0a-8f28-50529cfe49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#%matplotlib notebook\n",
    "\n",
    "from sax_synth_inference import run_on_validation_set, g_mel, load_generator_model, synthetic2octaves, generate_from_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75790f5b-71f2-4edd-9d84-6088cec4f87b",
   "metadata": {},
   "source": [
    "# Init the generator and Mel spec class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef28a06-3f6f-4d8c-b047-777c666bb908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "gen_path = '../results/2023_05_28_hifigan_ssynth44khz_synthesized_input_16k_spl0.5_nonorm/hifigan_gen_checkpoint_3000.pt'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' # 'cuda'\n",
    "gen, denoiser, train_cfg = load_generator_model(gen_path, device = DEVICE)\n",
    "sampling_rate = train_cfg['sampling_rate']\n",
    "MEL_IMPL = 'hifigan'\n",
    "g_mel.init(train_cfg, MEL_IMPL)\n",
    "print('done loading generator')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2431db-5f14-4ad0-b985-04e8bbaf7f7b",
   "metadata": {},
   "source": [
    "# Run inference on validation set, optionally sample one file to play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3af353-6fad-4d8f-8617-be8b93877d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "flist_path = '../data_ssynth/filelists' #--- where to look for list of validation files\n",
    "num_files = 2 #--- take first N files of the whole validation set (optional)\n",
    "mel_loss, mel_len, yret, times_lens = run_on_validation_set(gen, denoiser, flist_path, num_files, return_file_index = 0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b06938b7-cba1-44ce-8b86-c2361ef0a713",
   "metadata": {},
   "source": [
    "#-- run-time to audio length ratio (per file)\n",
    "import numpy as np\n",
    "a = np.array(times_lens)\n",
    "a[:,0] / a[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cdec93-a3f4-43c6-8fb9-f94e8bc60523",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_normalize = True #False\n",
    "\n",
    "print('Original audio:')\n",
    "ipd.display(ipd.Audio(yret['y'], rate = sampling_rate, normalize = play_normalize))\n",
    "\n",
    "#print('Synthesized input:')\n",
    "#ipd.display(ipd.Audio(y_, rate = sampling_rate, normalize = play_normalize))\n",
    "\n",
    "print('Generated audio:')\n",
    "ipd.display(ipd.Audio(yret['y_hat'], rate = sampling_rate, normalize = play_normalize))\n",
    "\n",
    "print('Generated audio (denoised):')\n",
    "ipd.display(ipd.Audio(yret['y_hat_den'], rate = sampling_rate, normalize = play_normalize))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8437a4-49b4-4da9-ba32-7d779d53388b",
   "metadata": {},
   "source": [
    "# Generate from synthetic input (2 octaves major scale)\n",
    "This uses naive linear envelopes, so it is expected to sound not natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe16d6-739c-4b5b-89eb-ffbf391f9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat, x_hat_den = synthetic2octaves(gen, denoiser, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3f90b2-bdab-44f1-aaac-4702b86e10e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_normalize = True #False\n",
    "\n",
    "print('Generated audio:')\n",
    "x_hat_ = x_hat[0].cpu().detach().numpy()[0]\n",
    "ipd.display(ipd.Audio(x_hat_, rate = sampling_rate, normalize = play_normalize))\n",
    "\n",
    "print('Generated audio (denoised):')\n",
    "x_hat_den_ = x_hat_den[0].cpu().detach().numpy()[0]\n",
    "ipd.display(ipd.Audio(x_hat_den_, rate = sampling_rate, normalize = play_normalize))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d97fff7-def5-4a91-a456-c9e766bcc4d0",
   "metadata": {},
   "source": [
    "# Generate from parallel audio+midi, and compare\n",
    "## 1. Generate using the real GT envelopes (pitch and amplitude) of the input audio.\n",
    "This step uses the midi data of notes on/off for better tracking.\n",
    "### Read midi file and phrase data, choose a phrase (by index), and generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ba4fe7-22b5-40f6-b803-9582e905fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssynth.set_python_path\n",
    "\n",
    "from ssynth.utils.synthesis import wav_midi_to_synth\n",
    "from ssynth.utils import midi\n",
    "from ssynth.utils.midi import midi_phrase_from_dataframe\n",
    "\n",
    "import librosa\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#--- read phrase info for 1 file\n",
    "if False:\n",
    "    file_id = 'Funky_Nadley'\n",
    "    midi_fnm = f'../data_ssynth_TMP/midi/{file_id}.mid'\n",
    "    data_dir = '../data_ssynth_TMP/wavs'\n",
    "    phrase_df_fnm = '../data_ssynth_TMP/phrase_df.csv'\n",
    "else:\n",
    "    file_id = '01_Free_Improv_dynamic_mic'\n",
    "    midi_fnm = f'../data_ssynth/auto_midi/{file_id}.mid'\n",
    "    data_dir = '../data_ssynth/wavs'\n",
    "    phrase_df_fnm = '../data_ssynth/phrase_df.csv'\n",
    "\n",
    "print(f'reading midi file {os.path.basename(midi_fnm)}')\n",
    "midi_df, midi_pitch, midi_aftertouch, midi_cc = midi.read_midi_to_df(midi_fnm)\n",
    "midi.verify_midi(midi_df)\n",
    "\n",
    "\n",
    "phrase_df = pd.read_csv(phrase_df_fnm, index_col = 0).reset_index(drop = True)\n",
    "phrase_df = phrase_df[phrase_df.file_nm.str.contains(file_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2938f0f-9216-4613-a1a5-e860c3c06a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- pitch detection config\n",
    "pd_cfg = dict(win = 1024,\n",
    "              ac_win = 512, # autocorrelation window\n",
    "              hop = 256)\n",
    "\n",
    "#--- choose a phrase (locally I copied a small number of files:)\n",
    "#---     Phrases from \"Funky_Nadley_dynamic_mic\": 5,42,14,12\n",
    "#---     Phrases from \"01_Free_Improv_dynamic_mic\": 14,17,26,30\n",
    "phrase_ind = 26\n",
    "p = phrase_df.iloc[phrase_ind]\n",
    "\n",
    "t0 = p.sample_start / sampling_rate\n",
    "wav_fnm = f'{data_dir}/{p.phrase_id}.wav'\n",
    "seg, sr = librosa.load(wav_fnm, sr = sampling_rate)\n",
    "\n",
    "midi_p = midi_phrase_from_dataframe(p, midi_df, sampling_rate)\n",
    "midi_p_cc = midi_phrase_from_dataframe(p, midi_cc, sampling_rate)\n",
    "\n",
    "#--- filter 'errors'\n",
    "min_velocity = 0 # some \"real\" notes have velocity 1, so we cannot filter errors based on velocity (so set threshold to 0)\n",
    "err_notes = (midi_p.type == 'note_on') & (midi_p.velocity <= min_velocity)\n",
    "err_notes.loc[err_notes[err_notes].index + 1] = True #--- add the corresponding note-off\n",
    "midi_p = midi_p[~err_notes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9068d0-3419-4a04-965e-bae1491b018a",
   "metadata": {},
   "source": [
    "### Generate and play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03ec570-f928-4410-bd03-3fa294514a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, env, freq = phrase_to_synth(seg, sr, midi_p, t0, num_harmonics = 30, spline_smoothing = 2, verbose = False)\n",
    "x, env, freq, _ = wav_midi_to_synth(seg, sr, midi_p, t0, pd_cfg, max_freq_hz = 16000, spline_smoothing = .5, verbose = False)\n",
    "\n",
    "#--- apply hifi-gan\n",
    "pre_gain = 1 #0.6\n",
    "x_hat = generate_from_audio(pre_gain * x, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b1c36-6119-48ed-9935-543f362ceb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_normalize = False\n",
    "play_rate_factor = 1 # .5\n",
    "ipd.display(ipd.Audio(seg, rate = play_rate_factor * sr, normalize=play_normalize))\n",
    "ipd.display(ipd.Audio(x_hat, rate = play_rate_factor * sr, normalize=play_normalize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bceb49-878d-45fc-8fa8-053ab223d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssynth.utils.synthesis import additive_synth_sawtooth\n",
    "\n",
    "x1_s = additive_synth_sawtooth(freq, env, sampling_rate, max_freq_hz = 16000)\n",
    "\n",
    "freq[freq < 1] = 0\n",
    "freq_q = librosa.midi_to_hz(np.round(librosa.hz_to_midi(freq))) #--- quantize frequency to notes\n",
    "x1_s_q = additive_synth_sawtooth(freq_q, env, sampling_rate, max_freq_hz = 16000)\n",
    "\n",
    "x1 = generate_from_audio(x1_s, gen, return_numpy_arr = True)\n",
    "x1_q = generate_from_audio(x1_s_q, gen, return_numpy_arr = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb645b-c642-445a-8c76-6893dd728c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_normalize = False\n",
    "ipd.display(ipd.Audio(x1, rate = play_rate_factor * sr, normalize=play_normalize))\n",
    "ipd.display(ipd.Audio(x1_q, rate = play_rate_factor * sr, normalize=play_normalize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c61b6-d06f-4a86-b741-2d4b158a93b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(figsize = (12,4))\n",
    "ax.plot(np.arange(len(env)) / sampling_rate, env,'o')\n",
    "try:\n",
    "    c = env.max() / midi_p_cc.value.max() # normalize view\n",
    "    ax.plot(midi_p_cc.ts_sec - t0, c * midi_p_cc.value,'.-')\n",
    "except:\n",
    "    pass\n",
    "ax.legend(['audio amplitude envelope', 'midi cc value'])\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c411e-f29d-4ab4-be89-7cd0e4108cb6",
   "metadata": {},
   "source": [
    "## 2. Generate from midi, using synthetic envelopes (pitch and amplitude)\n",
    "### Side task: fit amplitude envelope for synthesis from midi\n",
    "choose a note and fit (manually...) an ADSR env using cubic-Bezier curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6189c33-9f92-4d3a-8cb6-5c50f4789394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import ssynth.utils.envelopes\n",
    "importlib.reload(ssynth.utils.envelopes)\n",
    "\n",
    "from ssynth.utils.envelopes import ADSRBezier\n",
    "from scipy.interpolate import CubicSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdfacf3-b67e-4ecc-92f5-f37e260db8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- compare 2 spline smoothing params (0.5 was used for training)\n",
    "%matplotlib widget\n",
    "x1, env1, freq1 = wav_midi_to_synth(seg, sr, midi_p, t0, pd_cfg, max_freq_hz=16000, spline_smoothing = 2, verbose = False)\n",
    "x2, env2, freq2 = wav_midi_to_synth(seg, sr, midi_p, t0, pd_cfg, max_freq_hz=16000, spline_smoothing = .5, verbose = False)\n",
    "k1, k2 = 52283, 67500\n",
    "env0 = env1[k1:k2] # use this to manually fit an ADSR env using Bezier etc.\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (14,6))\n",
    "ax.plot(env1,'.')\n",
    "ax.plot(env2,':')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7e1ba2f-f666-4166-a736-2626d0355100",
   "metadata": {},
   "source": [
    "#%matplotlib widget\n",
    "from matplotlib.patches import Polygon\n",
    "assert (phrase_ind == 42 and file_id == 'Funky_Nadley'), 'the following params were manually chosen based on file \"Funky_Nadley\" and phrase 42, make sure to use the same file and phrase'\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (14,6))\n",
    "#ax.plot(env1,'.')\n",
    "#ax.plot(env2,':')\n",
    "adsr = np.array([0, 1900, 3600, 8100, len(env0) - 1])\n",
    "n0, n1, n2, n3, n4 = adsr\n",
    "e0, e1, e2, e3, e4 = [env0[k] for k in adsr]\n",
    "ax.plot(env0, '.-')\n",
    "\n",
    "a = e1\n",
    "cols = ['b', 'r', 'g', 'c']\n",
    "for k in range(4):\n",
    "    poly = Polygon([[adsr[k], 0], [adsr[k+1], 0], [adsr[k+1], a], [adsr[k],a]], facecolor=cols[k], alpha = 0.15, edgecolor='0.2', closed=True)\n",
    "    ax.add_patch(poly)\n",
    "\n",
    "nA, nD, nS, nR = np.diff(adsr)\n",
    "\n",
    "#curveA = get_bezier_parameters(np.arange(adsr[1]), env0[:nA])\n",
    "#Ax, Ay =  bezier_curve(curveA, nA)\n",
    "\n",
    "#=== Attack\n",
    "Ax, Ay =  bezier_curve([[n0, e0],  [.8 * n1, e0],      [.5 * n1, e1],          [n1, e1]], nA)\n",
    "\n",
    "#=== Decay\n",
    "de1 = (e1 - e2)\n",
    "Dx, Dy =  bezier_curve([[n1, e1], [n1 + .5 * nD, e1], [n2 - .5 * nD, e2 + .4 * de1], [n2, e2]], nD)\n",
    "\n",
    "#--- Sustain\n",
    "de2 = (e2 - e3)\n",
    "Sx, Sy =  bezier_curve([[n2, e2], [n2 + .5 * nD, e2 - .4 * de1], [n3 - .4 * nS, e3 + .1 * de2], [n3, e3]], nS)\n",
    "\n",
    "#--- Release\n",
    "de3 = (e3 - e4)\n",
    "Rx, Ry =  bezier_curve([[n3, e3], [n3 + .4 * nS, e3 - .1 * de2], [n4 - 1.2 * nR, e4 + 0 * de3], [n4, e4]], nR)\n",
    "\n",
    "ax.plot(Ax, Ay, 'r')\n",
    "ax.plot(Dx, Dy, 'r')\n",
    "ax.plot(Sx, Sy, 'r')\n",
    "ax.plot(Rx, Ry, 'r')\n",
    "\n",
    "#--- compare with cubic spline\n",
    "spl = CubicSpline(adsr, [env0[k-1] for k in adsr], bc_type='clamped')\n",
    "env_spl = spl(np.arange(n4))\n",
    "ax.plot(env_spl, ':')\n",
    "\n",
    "#ax.plot(np.arange(len(env1)) - k1, env1,':')\n",
    "\n",
    "#ax.set_xlim([n1,15000])\n",
    "#ax.set_ylim([.1,.14])\n",
    "#ax.legend(['original envelope', 'piece-wise cubic Bezier', 'cubic spline'])\n",
    "ax.grid()\n",
    "fig.savefig('bezier_adsr.png')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1753eb3a-46d9-4acf-8283-2c8008cf2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adsr_cfg = dict(a_t_msec = 43, d_lvl = 0.85, d_t_msec = 39, s_lvl = 0.73, s_t_msec = 100, r_t_msec = 160)\n",
    "adsr_cfg_default = adsr_cfg.copy()\n",
    "\n",
    "adsr_cfg = dict(a_t_msec = 40, d_lvl = 0.8, d_t_msec = 35, s_lvl = 0.7, s_t_msec = 100, r_t_msec = 40)\n",
    "adsr_bez = ADSRBezier(adsr_cfg, sr)\n",
    "#env3 = adsr_bez.get_envelope(sustain_msec = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ba25fd-97b0-4517-aff3-3cf8c1b20972",
   "metadata": {},
   "source": [
    "### Plot ADSR env with the Bezier control points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f32318-eba9-42ba-b006-adeb68f0c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(figsize = (12,4))\n",
    "sustain_msec = 80\n",
    "env4, ctrl_p = adsr_bez.get_envelope(sustain_msec)\n",
    "a,d,s,r = ctrl_p\n",
    "\n",
    "#ax.plot(env1, 'o')\n",
    "#ax.plot(env2, 'r.')\n",
    "#ax.plot(env3, 'g.')\n",
    "ax.plot(env4, 'c.', markersize=1)\n",
    "for p in [a,d,s,r]:\n",
    "    p = np.array(p)\n",
    "    ax.plot(p[0:2,0], p[0:2,1], marker = 'x')\n",
    "    ax.plot(p[2:4,0], p[2:4,1], marker = 'o')\n",
    "\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f26e9cc-5112-43d1-bb11-079f7d4fe7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_notes = midi_p.shape[0]\n",
    "global_gain = .2\n",
    "last_k = -1\n",
    "onset_sec = (adsr_cfg['a_t_msec'] +  adsr_cfg['d_t_msec']) / 1000\n",
    "attack_samples = int(adsr_cfg['a_t_msec'] / 1000 * sr)\n",
    "\n",
    "phrase_dur_sec = midi_p.ts_sec.iloc[-1] - midi_p.ts_sec.iloc[0] + 1 #--- add a 1 sec tail for \"release\" of last note\n",
    "phrase_dur_samples = int(phrase_dur_sec * sr)\n",
    "env_midi = np.zeros(phrase_dur_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffecea65-6c45-4986-9a20-c84ad2d32a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig, ax = plt.subplots(figsize = (12,4))\n",
    "#--- if true, use midi note 'velocity' for gain. if false, extract from audio (which can be done only if we have the original phrase...)\n",
    "get_gain_from_midi = False\n",
    "'''\n",
    "#--- TODO\n",
    "- finish the x-fade impl\n",
    "- fix k_on, k_off below \n",
    "\n",
    "'''\n",
    "for k in np.arange(0, num_notes, 2):\n",
    "    row_on = midi_p.iloc[k]      \n",
    "    row_off = midi_p.iloc[k + 1]\n",
    "    \n",
    "    t_on, t_off = row_on.ts_sec, row_off.ts_sec\n",
    "    k_on, k_off = int((t_on - t0) * sr), int((t_off - t0) * sr)\n",
    "\n",
    "    if get_gain_from_midi:\n",
    "        gain = row_on.velocity / 127\n",
    "    else:\n",
    "        #--- the \"RMS\" but use 0.95 quantile instead of mean\n",
    "        gain = 4 * np.sqrt(np.quantile(seg[k_on:k_off] ** 2, 0.95))\n",
    "    \n",
    "    gain *= global_gain\n",
    "        \n",
    "\n",
    "    sustain_msec = (t_off - t_on - onset_sec) * 1000 #(k_off - k_on) * 1000 / sr\n",
    "    if sustain_msec < 15:\n",
    "        print(f'k={k}, t={t_on - t0:.2f}, sustain={sustain_msec:.1f} < 40 msec, skipping note, TODO')\n",
    "        continue\n",
    "    \n",
    "    env_k, _ = adsr_bez.get_envelope(sustain_msec, gain)\n",
    "    #--- cross-fade with last env\n",
    "    if k_on < last_k:\n",
    "        xfade_len = last_k - k_on       \n",
    "        fade_in = np.linspace(0, 1, min(attack_samples, xfade_len))\n",
    "        n_fade_in = fade_in.shape[0]\n",
    "        #--- check if we need to add a constant env\n",
    "        if n_fade_in < xfade_len:\n",
    "            fade_in = np.r_[fade_in, np.ones(xfade_len - n_fade_in)]\n",
    "        fade_out = 1 - fade_in\n",
    "        env_k[:xfade_len] *= fade_in\n",
    "        env_midi[k_on : last_k] *= fade_out\n",
    "\n",
    "    env_midi[k_on : k_on + len(env_k)] += env_k\n",
    "    #ax.plot(np.arange(k_on, k_on + len(env_k)) / sr, env_k, '.')\n",
    "    last_k = k_on + len(env_k)\n",
    "    #last_env = env\n",
    "\n",
    "ax.plot(np.arange(len(env)) / sr, env, 'k')\n",
    "ax.plot(np.arange(len(env_midi)) / sr, env_midi,'r')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b844c-8192-4462-9a26-588932599db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssynth.utils.synthesis import additive_synth_sawtooth\n",
    "env_midi = env_midi[:len(env)]\n",
    "x_midi = additive_synth_sawtooth(freq, env_midi, sampling_rate, max_freq_hz = 16000)\n",
    "x_midi_hat = generate_from_audio(x_midi, gen, return_numpy_arr = True)\n",
    "\n",
    "# denoised version\n",
    "denoising_strength = 2*0.05\n",
    "x_midi_hat_TMP = generate_from_audio(x_midi, gen, return_numpy_arr = False)\n",
    "x_midi_hat_den = denoiser(x_midi_hat_TMP.squeeze(1), denoising_strength).numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51ecc1a-5e68-4f33-bdc7-2db00be404c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_normalize = False\n",
    "ipd.display(ipd.Audio(seg, rate = sr, normalize=play_normalize))\n",
    "ipd.display(ipd.Audio(x_hat, rate = sr, normalize=play_normalize))\n",
    "ipd.display(ipd.Audio(x_midi_hat, rate = sr, normalize=play_normalize))\n",
    "ipd.display(ipd.Audio(x_midi_hat_den, rate = sr, normalize=play_normalize))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
